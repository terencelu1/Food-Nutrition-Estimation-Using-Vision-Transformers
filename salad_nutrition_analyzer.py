"""
æ²™æ‹‰ç‡Ÿé¤Šåˆ†æç³»çµ±
ä½¿ç”¨SAM (Segment Anything Model) å’Œ DPT-Hybrid (MiDaS) é€²è¡Œåœ–åƒåˆ†æå’Œç‡Ÿé¤Šè¨ˆç®—
"""

import cv2
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
import matplotlib.pyplot as plt
from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator
import os
import warnings
import time
import sys
import platform
warnings.filterwarnings('ignore')

# ç‡Ÿé¤Šæ•¸æ“šåº«ï¼ˆæ¯100å…‹çš„ç‡Ÿé¤Šä¿¡æ¯ï¼‰
NUTRITION_DB = {
    'ç”Ÿèœ': {'calories': 15, 'protein': 1.4, 'carbs': 2.9, 'fat': 0.2, 'fiber': 1.3},
    'ç•ªèŒ„': {'calories': 18, 'protein': 0.9, 'carbs': 3.9, 'fat': 0.2, 'fiber': 1.2},
    'é»ƒç“œ': {'calories': 16, 'protein': 0.7, 'carbs': 3.6, 'fat': 0.1, 'fiber': 0.5},
    'èƒ¡è˜¿è””': {'calories': 41, 'protein': 0.9, 'carbs': 9.6, 'fat': 0.2, 'fiber': 2.8},
    'ç‰ç±³': {'calories': 96, 'protein': 3.4, 'carbs': 21.3, 'fat': 1.2, 'fiber': 2.4},
    'é›è›‹': {'calories': 155, 'protein': 13, 'carbs': 1.1, 'fat': 11, 'fiber': 0},
    'é›èƒ¸è‚‰': {'calories': 165, 'protein': 31, 'carbs': 0, 'fat': 3.6, 'fiber': 0},
    'å …æœ': {'calories': 607, 'protein': 20, 'carbs': 21.6, 'fat': 54.4, 'fiber': 7},
    'èµ·å¸': {'calories': 371, 'protein': 23, 'carbs': 1.3, 'fat': 30, 'fiber': 0},
    'æ©„æ¬–': {'calories': 115, 'protein': 0.8, 'carbs': 6.0, 'fat': 10.7, 'fiber': 3.2},
    'æœªçŸ¥æˆåˆ†': {'calories': 50, 'protein': 2.0, 'carbs': 8.0, 'fat': 1.0, 'fiber': 2.0}
}

class SaladNutritionAnalyzer:
    def _print_environment_info(self):
        """æ‰“å°ç’°å¢ƒç‰ˆæœ¬ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ç’°å¢ƒä¿¡æ¯")
        print("="*60)
        print(f"è¨ˆç®—è¨­å‚™: {self.compute_device}")
        if torch.cuda.is_available():
            print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"GPUè¨­å‚™: {torch.cuda.get_device_name(0)}")
            print(f"GPUå…§å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"Pythonç‰ˆæœ¬: {sys.version.split()[0]}")
        print(f"æ“ä½œç³»çµ±: {platform.system()} {platform.release()}")
        
        # å˜—è©¦ç²å–å…¶ä»–åº«çš„ç‰ˆæœ¬ï¼ˆä½¿ç”¨å·²å°å…¥çš„æ¨¡å¡Šï¼‰
        try:
            print(f"OpenCVç‰ˆæœ¬: {cv2.__version__}")
        except:
            pass
        
        try:
            print(f"NumPyç‰ˆæœ¬: {np.__version__}")
        except:
            pass
        
        try:
            import segment_anything
            print(f"Segment Anythingç‰ˆæœ¬: {segment_anything.__version__ if hasattr(segment_anything, '__version__') else 'æœªçŸ¥'}")
        except:
            pass
        
        print("="*60 + "\n")
    
    def __init__(self, sam_checkpoint_path=None, dpt_model_type='dpt_hybrid', 
                 midas_path=None, result_dir='result'):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        Args:
            sam_checkpoint_path: SAMæ¨¡å‹æª¢æŸ¥é»è·¯å¾‘ï¼ˆå¦‚æœç‚ºNoneï¼Œå°‡è‡ªå‹•æŸ¥æ‰¾ï¼‰
            dpt_model_type: DPTæ¨¡å‹é¡å‹ï¼ˆ'dpt_hybrid', 'dpt_large', 'dpt_base'ï¼‰
            midas_path: æœ¬åœ°MiDaSæ¨¡å‹è³‡æ–™å¤¾è·¯å¾‘ï¼ˆå¦‚æœç‚ºNoneï¼Œå°‡è‡ªå‹•æŸ¥æ‰¾ï¼‰
            result_dir: çµæœä¿å­˜ç›®éŒ„
        """
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.compute_device = 'GPU (CUDA)' if torch.cuda.is_available() else 'CPU'
        
        # æ‰“å°ç’°å¢ƒä¿¡æ¯
        self._print_environment_info()
        
        # å‰µå»ºçµæœè³‡æ–™å¤¾
        self.result_dir = result_dir
        os.makedirs(self.result_dir, exist_ok=True)
        print(f"çµæœå°‡ä¿å­˜åˆ° '{self.result_dir}' è³‡æ–™å¤¾")
        
        # åˆå§‹åŒ–SAMæ¨¡å‹
        print("æ­£åœ¨è¼‰å…¥SAMæ¨¡å‹...")
        try:
            # è‡ªå‹•æŸ¥æ‰¾SAMæ¨¡å‹æ–‡ä»¶
            if sam_checkpoint_path is None:
                possible_paths = [
                    "sam_vit_h_4b8939.pth",
                    "sam_vit_h.pth",
                    "./sam_vit_h_4b8939.pth",
                    "./sam_vit_h.pth"
                ]
                sam_checkpoint_path = None
                for path in possible_paths:
                    if os.path.exists(path):
                        sam_checkpoint_path = path
                        print(f"æ‰¾åˆ°SAMæ¨¡å‹: {path}")
                        break
                
                if sam_checkpoint_path is None:
                    print("æœªæ‰¾åˆ°SAMæ¨¡å‹æ–‡ä»¶ï¼Œè«‹ç¢ºä¿æ¨¡å‹æ–‡ä»¶åœ¨ç•¶å‰ç›®éŒ„")
                    print("å¾ä»¥ä¸‹ç¶²å€ä¸‹è¼‰: https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth")
                    raise FileNotFoundError("SAMæ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°")
            
            self.sam_model = sam_model_registry["vit_h"](checkpoint=sam_checkpoint_path)
            self.sam_model.to(device=self.device)
            self.sam_predictor = SamPredictor(self.sam_model)
            # å‰µå»ºè‡ªå‹•maskç”Ÿæˆå™¨ï¼ˆç”¨æ–¼æ›´å¥½çš„åˆ†å‰²ï¼‰
            self.sam_mask_generator = SamAutomaticMaskGenerator(
                self.sam_model,
                points_per_side=32,  # å¢åŠ æ¡æ¨£é»å¯†åº¦
                pred_iou_thresh=0.86,
                stability_score_thresh=0.92,
                crop_n_layers=1,
                crop_n_points_downscale_factor=2,
                min_mask_region_area=100,  # æœ€å°å€åŸŸé¢ç©ï¼ˆåƒç´ ï¼‰
            )
            print("âœ“ SAMæ¨¡å‹è¼‰å…¥å®Œæˆ")
        except Exception as e:
            print(f"âœ— SAMæ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            print("å°‡ä½¿ç”¨ç°¡åŒ–ç‰ˆåˆ†å‰²åŠŸèƒ½")
            self.sam_predictor = None
        
        # åˆå§‹åŒ–DPTæ¨¡å‹
        print("æ­£åœ¨è¼‰å…¥DPT-Hybridæ¨¡å‹...")
        try:
            # è‡ªå‹•æŸ¥æ‰¾æœ¬åœ°MiDaSè³‡æ–™å¤¾
            if midas_path is None:
                possible_midas_paths = [
                    "D:\\AI_CODE\\isl-org-MiDaS-4545977",
                    "./isl-org-MiDaS-4545977",
                    "../isl-org-MiDaS-4545977",
                    "isl-org-MiDaS-4545977"
                ]
                midas_path = None
                for path in possible_midas_paths:
                    if os.path.exists(path) and os.path.exists(os.path.join(path, "hubconf.py")):
                        midas_path = path
                        print(f"æ‰¾åˆ°æœ¬åœ°MiDaSæ¨¡å‹: {path}")
                        break
            
            if midas_path and os.path.exists(midas_path):
                # å¾æœ¬åœ°MiDaSè³‡æ–™å¤¾è¼‰å…¥
                if midas_path not in sys.path:
                    sys.path.insert(0, midas_path)
                
                # è¼‰å…¥hubconfä¸¦ç²å–æ¨¡å‹å‡½æ•¸
                import importlib.util
                hubconf_path = os.path.join(midas_path, "hubconf.py")
                spec = importlib.util.spec_from_file_location("hubconf", hubconf_path)
                hubconf = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(hubconf)
                
                # æ ¹æ“šæ¨¡å‹é¡å‹é¸æ“‡å°æ‡‰çš„å‡½æ•¸
                if dpt_model_type == 'dpt_hybrid':
                    self.dpt_model = hubconf.DPT_Hybrid(pretrained=True)
                elif dpt_model_type == 'dpt_large':
                    self.dpt_model = hubconf.DPT_Large(pretrained=True)
                elif dpt_model_type == 'dpt_beit_large_384':
                    self.dpt_model = hubconf.DPT_BEiT_L_384(pretrained=True)
                elif dpt_model_type == 'dpt_beit_base_384':
                    self.dpt_model = hubconf.DPT_BEiT_B_384(pretrained=True)
                else:
                    # é»˜èªä½¿ç”¨DPT_Hybrid
                    self.dpt_model = hubconf.DPT_Hybrid(pretrained=True)
                
                self.dpt_model.to(self.device)
                self.dpt_model.eval()
                print(f"âœ“ DPTæ¨¡å‹è¼‰å…¥å®Œæˆï¼ˆå¾æœ¬åœ°: {midas_path}ï¼‰")
            else:
                # å¦‚æœæ‰¾ä¸åˆ°æœ¬åœ°æ¨¡å‹ï¼Œä½¿ç”¨torch.hubå¾ç¶²ä¸Šä¸‹è¼‰
                print("æœªæ‰¾åˆ°æœ¬åœ°MiDaSæ¨¡å‹ï¼Œå°‡å¾ç¶²ä¸Šä¸‹è¼‰...")
                model_map = {
                    'dpt_hybrid': 'DPT_Hybrid',
                    'dpt_large': 'DPT_Large',
                    'dpt_beit_large_384': 'DPT_BEiT_L_384',
                    'dpt_beit_base_384': 'DPT_BEiT_B_384'
                }
                hub_function = model_map.get(dpt_model_type, 'DPT_Hybrid')
                self.dpt_model = torch.hub.load('intel-isl/MiDaS', hub_function)
                self.dpt_model.to(self.device)
                self.dpt_model.eval()
                print("âœ“ DPTæ¨¡å‹è¼‰å…¥å®Œæˆï¼ˆå¾ç¶²è·¯ä¸‹è¼‰ï¼‰")
        except Exception as e:
            print(f"âœ— DPTæ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            self.dpt_model = None
    
    def load_image(self, image_path):
        """è¼‰å…¥åœ–åƒ"""
        if isinstance(image_path, str):
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"ç„¡æ³•è¼‰å…¥åœ–åƒ: {image_path}")
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            image_rgb = np.array(image_path)
            if len(image_rgb.shape) == 3 and image_rgb.shape[2] == 4:
                image_rgb = image_rgb[:, :, :3]
        
        # ä¿å­˜åŸå§‹åœ–åƒ
        self.save_image(image_rgb, '01_original_image.jpg')
        
        return image_rgb
    
    def save_image(self, image, filename):
        """ä¿å­˜åœ–åƒåˆ°resultè³‡æ–™å¤¾"""
        filepath = os.path.join(self.result_dir, filename)
        if len(image.shape) == 2 or image.shape[2] == 1:
            # ç°åº¦åœ–
            cv2.imwrite(filepath, image)
        else:
            # RGBåœ–åƒï¼Œéœ€è¦è½‰æ›ç‚ºBGR
            if image.dtype != np.uint8:
                image = (image * 255).astype(np.uint8)
            image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            cv2.imwrite(filepath, image_bgr)
        print(f"  å·²ä¿å­˜: {filepath}")
    
    def segment_image_with_sam(self, image_rgb):
        """
        ä½¿ç”¨SAMé€²è¡Œåœ–åƒåˆ†å‰²ï¼ˆæ”¹é€²ç‰ˆï¼šä½¿ç”¨è‡ªå‹•maskç”Ÿæˆï¼‰
        """
        if self.sam_predictor is None:
            # ç°¡åŒ–ç‰ˆåˆ†å‰²ï¼šä½¿ç”¨é¡è‰²å’Œç´‹ç†ç‰¹å¾µ
            return self.simplified_segmentation(image_rgb)
        
        try:
            h, w = image_rgb.shape[:2]
            
            # ä½¿ç”¨è‡ªå‹•maskç”Ÿæˆå™¨ä¾†ç²å–æ‰€æœ‰å¯èƒ½çš„ç‰©é«”mask
            print("  æ­£åœ¨ä½¿ç”¨SAMè‡ªå‹•maskç”Ÿæˆ...")
            if hasattr(self, 'sam_mask_generator'):
                # ä½¿ç”¨è‡ªå‹•maskç”Ÿæˆå™¨
                sam_start = time.time()
                masks = self.sam_mask_generator.generate(image_rgb)
                sam_time = time.time() - sam_start
                print(f"  SAMæ¨ç†æ™‚é–“: {sam_time:.2f} ç§’")
            else:
                # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ›´å¯†é›†çš„é»æ¡æ¨£
                self.sam_predictor.set_image(image_rgb)
                
                # æ›´å¯†é›†çš„ç¶²æ ¼æ¡æ¨£ï¼ˆ5x5 = 25å€‹é»ï¼‰
                step_h, step_w = h // 5, w // 5
                all_masks_data = []
                
                for i in range(1, 6):
                    for j in range(1, 6):
                        point_coords = np.array([[step_h * i, step_w * j]])
                        point_labels = np.array([1])
                        
                        masks_pred, scores, logits = self.sam_predictor.predict(
                            point_coords=point_coords,
                            point_labels=point_labels,
                            multimask_output=True
                        )
                        
                        # ä¿å­˜æ‰€æœ‰maskï¼ˆä¸åªæ˜¯æœ€å¥½çš„ï¼‰
                        for mask_idx, mask in enumerate(masks_pred):
                            if scores[mask_idx] > 0.7:  # åªä¿ç•™é«˜åˆ†çš„mask
                                all_masks_data.append({
                                    'segmentation': mask,
                                    'stability_score': scores[mask_idx],
                                    'area': mask.sum()
                                })
                
                masks = all_masks_data
            
            if not masks:
                print("  è­¦å‘Š: æœªç”Ÿæˆä»»ä½•maskï¼Œä½¿ç”¨å‚™ç”¨åˆ†å‰²æ–¹æ³•")
                return self.simplified_segmentation(image_rgb)
            
            # éæ¿¾å’Œæ•´ç†masks
            print(f"  ç”Ÿæˆäº† {len(masks)} å€‹å€™é¸mask")
            
            # æŒ‰ç©©å®šæ€§åˆ†æ•¸æ’åºï¼Œä¿ç•™æœ€å¥½çš„masks
            if isinstance(masks[0], dict):
                masks = sorted(masks, key=lambda x: x.get('stability_score', x.get('predicted_iou', 0)), reverse=True)
                # åªä¿ç•™å‰50å€‹æœ€å¥½çš„masks
                masks = masks[:50]
                mask_segmentations = [m['segmentation'] for m in masks]
            else:
                mask_segmentations = masks
            
            # å»é‡å’Œåˆä½µé‡ç–Šçš„masks
            segments = []
            used_mask = np.zeros((h, w), dtype=bool)
            segment_vis = image_rgb.copy().astype(np.float32)
            colors = plt.cm.Set3(np.linspace(0, 1, len(mask_segmentations)))
            
            # ä¿å­˜æ‰€æœ‰åŸå§‹masksçš„å¯è¦–åŒ–
            mask_vis = np.zeros((h, w, 3), dtype=np.uint8)
            for mask in mask_segmentations[:20]:  # åªé¡¯ç¤ºå‰20å€‹
                mask_bool = mask.astype(bool) if mask.dtype != bool else mask
                mask_vis[mask_bool] = [255, 255, 255]
            self.save_image(mask_vis, '02_sam_all_masks.jpg')
            
            # é¸æ“‡ç¨ç«‹çš„ã€ä¸é‡ç–Šçš„å€åŸŸ
            for idx, mask in enumerate(mask_segmentations):
                mask_bool = mask.astype(bool) if mask.dtype != bool else mask
                mask_area = mask_bool.sum()
                
                # éæ¿¾å¤ªå°æˆ–å¤ªå¤§çš„å€åŸŸ
                if mask_area < 100 or mask_area > (h * w * 0.8):
                    continue
                
                # è¨ˆç®—èˆ‡å·²ä½¿ç”¨å€åŸŸçš„é‡ç–Šåº¦
                overlap = np.logical_and(used_mask, mask_bool).sum()
                overlap_ratio = overlap / mask_area if mask_area > 0 else 0
                
                # å¦‚æœé‡ç–Šåº¦å°æ–¼30%ï¼Œèªç‚ºæ˜¯æ–°çš„ç¨ç«‹å€åŸŸ
                if overlap_ratio < 0.3:
                    segments.append(mask_bool)
                    used_mask = np.logical_or(used_mask, mask_bool)
                    
                    # ç‚ºå¯è¦–åŒ–æ·»åŠ é¡è‰²ï¼ˆåŠé€æ˜è¦†è“‹ï¼‰
                    color = np.array(colors[idx][:3]) * 255
                    segment_vis[mask_bool] = segment_vis[mask_bool] * 0.6 + color * 0.4
            
            print(f"  æœ€çµ‚è­˜åˆ¥åˆ° {len(segments)} å€‹ç¨ç«‹å€åŸŸ")
            
            # ç‚ºæ¯å€‹åˆ†å‰²å€åŸŸç¹ªè£½è—è‰²é‚Šç·£ç·šï¼ˆæ²¿è‘—å¯¦éš›è¼ªå»“ï¼‰
            segment_vis_with_boxes = segment_vis.copy()
            for segment_mask in segments:
                # å°‡maskè½‰æ›ç‚ºuint8æ ¼å¼ç”¨æ–¼è¼ªå»“æª¢æ¸¬
                mask_uint8 = (segment_mask.astype(np.uint8) * 255)
                
                # æ‰¾åˆ°maskçš„è¼ªå»“
                contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                # ç¹ªè£½è—è‰²è¼ªå»“ç·š
                edge_thickness = max(2, int(min(h, w) / 400))  # æ ¹æ“šåœ–åƒå¤§å°èª¿æ•´ç·šæ¢ç²—ç´°
                
                # è½‰æ›ç‚ºBGRæ ¼å¼ä»¥ä¾¿ä½¿ç”¨cv2.drawContours
                segment_vis_bgr = cv2.cvtColor(segment_vis_with_boxes.astype(np.uint8), cv2.COLOR_RGB2BGR)
                
                # ç¹ªè£½è—è‰²è¼ªå»“ï¼ˆBGRæ ¼å¼ä¸­è—è‰²æ˜¯(255, 0, 0)ï¼‰
                cv2.drawContours(segment_vis_bgr, contours, -1, (255, 0, 0), edge_thickness)
                
                # è½‰å›RGBæ ¼å¼
                segment_vis_with_boxes = cv2.cvtColor(segment_vis_bgr, cv2.COLOR_BGR2RGB).astype(np.float32)
            
            # ä¿å­˜åˆ†å‰²çµæœï¼ˆå¸¶è—è‰²é‚Šæ¡†ï¼‰
            if len(segments) > 0:
                self.save_image(segment_vis_with_boxes.astype(np.uint8), '03_sam_segmentation_result.jpg')
            else:
                # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç¨ç«‹å€åŸŸï¼Œä½¿ç”¨ç¬¬ä¸€å€‹mask
                if mask_segmentations:
                    mask_bool = mask_segmentations[0].astype(bool) if mask_segmentations[0].dtype != bool else mask_segmentations[0]
                    segments.append(mask_bool)
                    segment_vis = image_rgb.copy().astype(np.float32)
                    segment_vis[mask_bool] = segment_vis[mask_bool] * 0.7 + np.array([0, 255, 0]) * 0.3
                    
                    # ç¹ªè£½è—è‰²é‚Šç·£ç·šï¼ˆæ²¿è‘—å¯¦éš›è¼ªå»“ï¼‰
                    mask_uint8 = (mask_bool.astype(np.uint8) * 255)
                    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    edge_thickness = max(2, int(min(h, w) / 400))
                    
                    # è½‰æ›ç‚ºBGRæ ¼å¼ä»¥ä¾¿ä½¿ç”¨cv2.drawContours
                    segment_vis_bgr = cv2.cvtColor(segment_vis.astype(np.uint8), cv2.COLOR_RGB2BGR)
                    cv2.drawContours(segment_vis_bgr, contours, -1, (255, 0, 0), edge_thickness)
                    segment_vis = cv2.cvtColor(segment_vis_bgr, cv2.COLOR_BGR2RGB).astype(np.float32)
                    
                    self.save_image(segment_vis.astype(np.uint8), '03_sam_segmentation_result.jpg')
            
            return segments if segments else [np.ones((h, w), dtype=bool)]
            
        except Exception as e:
            print(f"SAMåˆ†å‰²éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            return self.simplified_segmentation(image_rgb)
    
    def simplified_segmentation(self, image_rgb):
        """ç°¡åŒ–ç‰ˆåˆ†å‰²ï¼ˆç•¶SAMä¸å¯ç”¨æ™‚ï¼‰"""
        # è½‰æ›ç‚ºHSVè‰²å½©ç©ºé–“
        hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)
        
        # ä½¿ç”¨K-meansèšé¡é€²è¡Œåˆ†å‰²
        from sklearn.cluster import KMeans
        
        # é‡å¡‘åœ–åƒ
        pixels = image_rgb.reshape(-1, 3)
        
        # K-meansèšé¡ï¼ˆå‡è¨­æ²™æ‹‰æœ‰5-7ç¨®ä¸»è¦æˆåˆ†ï¼‰
        n_clusters = 6
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        labels = kmeans.fit_predict(pixels)
        labels = labels.reshape(image_rgb.shape[:2])
        
        # ç‚ºæ¯å€‹èšé¡å‰µå»ºmask
        segments = []
        segment_vis = image_rgb.copy().astype(np.float32)
        colors = plt.cm.Set3(np.linspace(0, 1, n_clusters))
        
        for i in range(n_clusters):
            mask = (labels == i).astype(np.uint8)
            if np.sum(mask) > 500:  # éæ¿¾å°å€åŸŸ
                segments.append(mask.astype(bool))
                # ç‚ºå¯è¦–åŒ–æ·»åŠ é¡è‰²
                color = np.array(colors[i][:3]) * 255
                segment_vis[mask > 0] = segment_vis[mask > 0] * 0.6 + color * 0.4
        
        # ç‚ºæ¯å€‹åˆ†å‰²å€åŸŸç¹ªè£½è—è‰²é‚Šç·£ç·šï¼ˆæ²¿è‘—å¯¦éš›è¼ªå»“ï¼‰
        h, w = image_rgb.shape[:2]
        # è½‰æ›ç‚ºBGRæ ¼å¼ä»¥ä¾¿ä½¿ç”¨cv2.drawContours
        segment_vis_bgr = cv2.cvtColor(segment_vis.astype(np.uint8), cv2.COLOR_RGB2BGR)
        
        for segment_mask in segments:
            # å°‡maskè½‰æ›ç‚ºuint8æ ¼å¼ç”¨æ–¼è¼ªå»“æª¢æ¸¬
            mask_uint8 = (segment_mask.astype(np.uint8) * 255)
            
            # æ‰¾åˆ°maskçš„è¼ªå»“
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # ç¹ªè£½è—è‰²è¼ªå»“ç·š
            edge_thickness = max(2, int(min(h, w) / 400))
            cv2.drawContours(segment_vis_bgr, contours, -1, (255, 0, 0), edge_thickness)
        
        # è½‰å›RGBæ ¼å¼
        segment_vis = cv2.cvtColor(segment_vis_bgr, cv2.COLOR_BGR2RGB).astype(np.float32)
        
        # ä¿å­˜åˆ†å‰²çµæœï¼ˆå¸¶è—è‰²é‚Šæ¡†ï¼‰
        self.save_image(segment_vis.astype(np.uint8), '03_kmeans_segmentation_result.jpg')
        
        return segments if segments else [np.ones(image_rgb.shape[:2], dtype=bool)]
    
    def estimate_depth_with_dpt(self, image_rgb):
        """
        ä½¿ç”¨DPT-Hybridä¼°è¨ˆæ·±åº¦åœ–
        """
        if self.dpt_model is None:
            # è¿”å›å‡è¨­çš„æ·±åº¦åœ–
            h, w = image_rgb.shape[:2]
            depth = np.ones((h, w), dtype=np.float32)
            # ä¿å­˜å‡è¨­çš„æ·±åº¦åœ–
            depth_vis = (depth * 255).astype(np.uint8)
            self.save_image(depth_vis, '04_dpt_depth_map.jpg')
            return depth
        
        try:
            # è½‰æ›ç‚ºtorch tensor
            img_tensor = torch.from_numpy(image_rgb).permute(2, 0, 1).float()
            img_tensor = img_tensor.unsqueeze(0).to(self.device)
            
            # èª¿æ•´å¤§å°ä»¥ç¬¦åˆæ¨¡å‹è¼¸å…¥
            img_tensor = F.interpolate(
                img_tensor, 
                size=(384, 384), 
                mode='bilinear', 
                align_corners=False
            )
            
            # é æ¸¬æ·±åº¦
            dpt_start = time.time()
            with torch.no_grad():
                depth = self.dpt_model(img_tensor)
                depth = F.interpolate(
                    depth.unsqueeze(1),
                    size=image_rgb.shape[:2],
                    mode='bilinear',
                    align_corners=False
                ).squeeze().cpu().numpy()
            dpt_time = time.time() - dpt_start
            print(f"  DPTæ¨ç†æ™‚é–“: {dpt_time:.2f} ç§’")
            
            # æ­£è¦åŒ–æ·±åº¦å€¼
            depth = (depth - depth.min()) / (depth.max() - depth.min() + 1e-8)
            
            # ä¿å­˜æ·±åº¦åœ–ï¼ˆå¯è¦–åŒ–ç‰ˆæœ¬ï¼‰
            depth_vis = (depth * 255).astype(np.uint8)
            depth_colored = cv2.applyColorMap(depth_vis, cv2.COLORMAP_VIRIDIS)
            depth_colored_rgb = cv2.cvtColor(depth_colored, cv2.COLOR_BGR2RGB)
            self.save_image(depth_colored_rgb, '04_dpt_depth_map.jpg')
            
            return depth
            
        except Exception as e:
            print(f"DPTæ·±åº¦ä¼°è¨ˆéŒ¯èª¤: {e}")
            h, w = image_rgb.shape[:2]
            depth = np.ones((h, w), dtype=np.float32)
            depth_vis = (depth * 255).astype(np.uint8)
            self.save_image(depth_vis, '04_dpt_depth_map.jpg')
            return depth
    
    def estimate_volume(self, mask, depth_map, pixel_to_cm_ratio=0.1):
        """
        ä¼°ç®—æ¯å€‹åˆ†å‰²å€åŸŸçš„é«”ç©
        Args:
            mask: åˆ†å‰²mask
            depth_map: æ·±åº¦åœ–
            pixel_to_cm_ratio: åƒç´ åˆ°å˜ç±³çš„è½‰æ›æ¯”ä¾‹ï¼ˆéœ€è¦æ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´ï¼‰
        """
        # è¨ˆç®—maskå€åŸŸçš„é¢ç©ï¼ˆåƒç´ æ•¸ï¼‰
        area_pixels = np.sum(mask)
        
        # è¨ˆç®—è©²å€åŸŸçš„å¹³å‡æ·±åº¦
        region_depth = depth_map[mask]
        avg_depth = np.mean(region_depth) if len(region_depth) > 0 else 1.0
        
        # ä¼°ç®—é«”ç©ï¼ˆå‡è¨­ç‚ºåœ“æŸ±é«”ï¼‰
        # é¢ç©è½‰æ›ç‚ºcmÂ²
        area_cm2 = area_pixels * (pixel_to_cm_ratio ** 2)
        
        # æ·±åº¦è½‰æ›ç‚ºcmï¼ˆå‡è¨­æ·±åº¦ç¯„åœåœ¨0-10cmä¹‹é–“ï¼‰
        depth_cm = avg_depth * 10
        
        # é«”ç© = é¢ç© * æ·±åº¦
        volume_cm3 = area_cm2 * depth_cm
        
        # è½‰æ›ç‚ºé‡é‡ï¼ˆå‡è¨­å¯†åº¦ç´„ç‚º1 g/cmÂ³ï¼‰
        weight_grams = volume_cm3 * 1.0
        
        return weight_grams
    
    def identify_food_component(self, image_region):
        """
        è­˜åˆ¥é£Ÿç‰©æˆåˆ†ï¼ˆç°¡åŒ–ç‰ˆï¼šåŸºæ–¼é¡è‰²ç‰¹å¾µï¼‰
        å¯¦éš›æ‡‰ç”¨ä¸­æ‡‰è©²ä½¿ç”¨æ›´å…ˆé€²çš„åœ–åƒåˆ†é¡æ¨¡å‹
        """
        # ç¢ºä¿åœ–åƒå€åŸŸæœ‰æ•ˆ
        if image_region.size == 0 or len(image_region.shape) < 2:
            return 'æœªçŸ¥æˆåˆ†'
        
        # é‡å¡‘ç‚º2Dæ•¸çµ„ä»¥ä¾¿è¨ˆç®—å¹³å‡é¡è‰²
        if len(image_region.shape) == 3:
            pixels = image_region.reshape(-1, 3)
        else:
            pixels = image_region.reshape(-1, 1)
        
        # éæ¿¾æ‰é»‘è‰²/ç„¡æ•ˆåƒç´ ï¼ˆå¯èƒ½æ˜¯èƒŒæ™¯ï¼‰
        if len(pixels.shape) == 2 and pixels.shape[1] == 3:
            valid_pixels = pixels[(pixels.sum(axis=1) > 10)]  # éæ¿¾æ¥è¿‘é»‘è‰²çš„åƒç´ 
            if len(valid_pixels) == 0:
                return 'æœªçŸ¥æˆåˆ†'
            avg_color = np.mean(valid_pixels, axis=0)
        else:
            return 'æœªçŸ¥æˆåˆ†'
        
        # å°‡å¹³å‡é¡è‰²è½‰æ›ç‚ºHSV
        # å‰µå»ºä¸€å€‹1x1çš„RGBåœ–åƒä¾†è½‰æ›HSV
        avg_color_uint8 = np.clip(avg_color, 0, 255).astype(np.uint8)
        color_rgb = avg_color_uint8.reshape(1, 1, 3)
        color_hsv = cv2.cvtColor(color_rgb, cv2.COLOR_RGB2HSV)
        h, s, v = color_hsv[0, 0]
        
        # åŸºæ–¼é¡è‰²ç‰¹å¾µçš„ç°¡å–®åˆ†é¡
        if v < 50:  # å¾ˆæš—
            return 'æœªçŸ¥æˆåˆ†'
        elif h < 15 or h > 165:  # ç´…è‰²/é»ƒè‰²ç¯„åœ
            if avg_color[0] > 200 and avg_color[1] < 100:  # å¾ˆç´…ï¼Œä½ç¶ 
                return 'ç•ªèŒ„'
            elif avg_color[0] > 150 and avg_color[1] > 100:  # æ©™è‰²
                return 'èƒ¡è˜¿è””'
            else:
                return 'æœªçŸ¥æˆåˆ†'
        elif 15 < h < 45:  # é»ƒè‰²ç¯„åœ
            if avg_color[1] > 150:  # é«˜ç¶ è‰²å€¼ï¼ˆé»ƒè‰²ï¼‰
                return 'ç‰ç±³'
            else:
                return 'æœªçŸ¥æˆåˆ†'
        elif 45 < h < 75:  # ç¶ è‰²ç¯„åœ
            if s < 80 and v > 150:  # ä½é£½å’Œåº¦ã€é«˜äº®åº¦ï¼ˆæ·ºç¶ ï¼Œå¯èƒ½æ˜¯ç”Ÿèœï¼‰
                return 'ç”Ÿèœ'
            elif s > 80:  # é«˜é£½å’Œåº¦ï¼ˆæ·±ç¶ ï¼Œå¯èƒ½æ˜¯é»ƒç“œæˆ–å…¶ä»–ç¶ è‘‰è”¬èœï¼‰
                return 'é»ƒç“œ'
            else:
                return 'ç”Ÿèœ'
        elif 100 < h < 130:  # è—ç¶ è‰²ç¯„åœï¼ˆå¯èƒ½æ˜¯æŸäº›ç‰¹æ®Šè”¬èœï¼‰
            return 'æœªçŸ¥æˆåˆ†'
        else:
            return 'æœªçŸ¥æˆåˆ†'
    
    def calculate_nutrition(self, segments, image_rgb, depth_map):
        """
        è¨ˆç®—ç‡Ÿé¤Šæ•¸æ“š
        æœƒè‡ªå‹•åˆä½µç›¸åŒé¡å‹çš„æˆåˆ†ï¼Œé¿å…é‡è¤‡è¨ˆç®—
        """
        total_nutrition = {
            'calories': 0,
            'protein': 0,
            'carbs': 0,
            'fat': 0,
            'fiber': 0,
            'weight': 0
        }
        
        # å…ˆç”¨å­—å…¸ä¾†ç´¯åŠ ç›¸åŒé¡å‹çš„æˆåˆ†
        component_dict = {}
        
        for i, segment_mask in enumerate(segments):
            # æå–è©²å€åŸŸçš„åœ–åƒ
            masked_image = image_rgb.copy()
            masked_image[~segment_mask] = 0
            region_image = masked_image[
                np.any(segment_mask, axis=1)
            ][:, np.any(segment_mask, axis=0)]
            
            if region_image.size == 0:
                continue
            
            # è­˜åˆ¥é£Ÿç‰©æˆåˆ†
            food_type = self.identify_food_component(region_image)
            
            # ä¼°ç®—é‡é‡
            weight = self.estimate_volume(segment_mask, depth_map)
            
            # è¨ˆç®—ç‡Ÿé¤Šæ•¸æ“š
            nutrition_per_100g = NUTRITION_DB.get(food_type, NUTRITION_DB['æœªçŸ¥æˆåˆ†'])
            
            # å¦‚æœè©²é¡å‹å·²å­˜åœ¨ï¼Œç´¯åŠ é‡é‡å’Œç‡Ÿé¤Šå€¼
            if food_type in component_dict:
                component_dict[food_type]['weight_g'] += weight
                component_dict[food_type]['calories'] += weight * nutrition_per_100g['calories'] / 100
                component_dict[food_type]['protein'] += weight * nutrition_per_100g['protein'] / 100
                component_dict[food_type]['carbs'] += weight * nutrition_per_100g['carbs'] / 100
                component_dict[food_type]['fat'] += weight * nutrition_per_100g['fat'] / 100
                component_dict[food_type]['fiber'] += weight * nutrition_per_100g['fiber'] / 100
            else:
                # å‰µå»ºæ–°çš„æˆåˆ†è¨˜éŒ„
                component_dict[food_type] = {
                    'type': food_type,
                    'weight_g': weight,
                    'calories': weight * nutrition_per_100g['calories'] / 100,
                    'protein': weight * nutrition_per_100g['protein'] / 100,
                    'carbs': weight * nutrition_per_100g['carbs'] / 100,
                    'fat': weight * nutrition_per_100g['fat'] / 100,
                    'fiber': weight * nutrition_per_100g['fiber'] / 100,
                }
        
        # è½‰æ›ç‚ºåˆ—è¡¨æ ¼å¼
        component_details = list(component_dict.values())
        
        # æŒ‰é‡é‡æ’åºï¼ˆå¾å¤§åˆ°å°ï¼‰
        component_details.sort(key=lambda x: x['weight_g'], reverse=True)
        
        # è¨ˆç®—ç¸½ç‡Ÿé¤Šæ•¸æ“š
        for comp in component_details:
            total_nutrition['weight'] += comp['weight_g']
            total_nutrition['calories'] += comp['calories']
            total_nutrition['protein'] += comp['protein']
            total_nutrition['carbs'] += comp['carbs']
            total_nutrition['fat'] += comp['fat']
            total_nutrition['fiber'] += comp['fiber']
        
        return total_nutrition, component_details
    
    def analyze_salad(self, image_path, visualize=True):
        """
        åˆ†ææ²™æ‹‰åœ–åƒä¸¦è¿”å›ç‡Ÿé¤Šæ•¸æ“š
        Args:
            image_path: åœ–åƒè·¯å¾‘æˆ–PIL Imageå°è±¡
            visualize: æ˜¯å¦é¡¯ç¤ºå¯è¦–åŒ–çµæœ
        Returns:
            ç‡Ÿé¤Šæ•¸æ“šå­—å…¸å’Œæˆåˆ†è©³æƒ…
        """
        total_start_time = time.time()
        
        print("\n" + "="*60)
        print(f"æ­£åœ¨åˆ†æåœ–åƒ: {image_path}")
        print("="*60)
        
        # è¼‰å…¥åœ–åƒ
        print("\n[æ­¥é©Ÿ 1/4] è¼‰å…¥åŸå§‹åœ–åƒ...")
        step_start = time.time()
        image_rgb = self.load_image(image_path)
        step_time = time.time() - step_start
        print(f"  è€—æ™‚: {step_time:.2f} ç§’")
        
        # åœ–åƒåˆ†å‰²
        print("\n[æ­¥é©Ÿ 2/4] ä½¿ç”¨SAMé€²è¡Œåœ–åƒåˆ†å‰²...")
        step_start = time.time()
        segments = self.segment_image_with_sam(image_rgb)
        step_time = time.time() - step_start
        print(f"âœ“ è­˜åˆ¥åˆ° {len(segments)} å€‹æˆåˆ†å€åŸŸ")
        print(f"  ç¸½è€—æ™‚: {step_time:.2f} ç§’")
        
        # æ·±åº¦ä¼°è¨ˆ
        print("\n[æ­¥é©Ÿ 3/4] ä½¿ç”¨DPT-Hybridä¼°è¨ˆæ·±åº¦...")
        step_start = time.time()
        depth_map = self.estimate_depth_with_dpt(image_rgb)
        step_time = time.time() - step_start
        print("âœ“ æ·±åº¦åœ–å·²ç”Ÿæˆ")
        print(f"  ç¸½è€—æ™‚: {step_time:.2f} ç§’")
        
        # è¨ˆç®—ç‡Ÿé¤Šæ•¸æ“š
        print("\n[æ­¥é©Ÿ 4/4] è¨ˆç®—ç‡Ÿé¤Šæ•¸æ“š...")
        step_start = time.time()
        total_nutrition, component_details = self.calculate_nutrition(
            segments, image_rgb, depth_map
        )
        step_time = time.time() - step_start
        print("âœ“ ç‡Ÿé¤Šæ•¸æ“šè¨ˆç®—å®Œæˆ")
        print(f"  è€—æ™‚: {step_time:.2f} ç§’")
        
        # å¯è¦–åŒ–
        if visualize:
            print("\næ­£åœ¨ç”Ÿæˆæœ€çµ‚å¯è¦–åŒ–çµæœ...")
            step_start = time.time()
            self.visualize_results(image_rgb, segments, depth_map, total_nutrition, component_details)
            step_time = time.time() - step_start
            print(f"  è€—æ™‚: {step_time:.2f} ç§’")
        
        total_time = time.time() - total_start_time
        
        print(f"\n{'='*60}")
        print(f"æ‰€æœ‰è™•ç†çµæœå·²ä¿å­˜åˆ° '{self.result_dir}' è³‡æ–™å¤¾")
        print("="*60)
        print(f"\nâ±ï¸  ç¸½æ¨ç†æ™‚é–“: {total_time:.2f} ç§’ ({total_time/60:.2f} åˆ†é˜)")
        print(f"ğŸ“Š è¨ˆç®—è¨­å‚™: {self.compute_device}")
        print(f"ğŸ“ˆ è™•ç†é€Ÿåº¦: {1/total_time:.2f} åœ–åƒ/ç§’")
        print("="*60 + "\n")
        
        return total_nutrition, component_details
    
    def visualize_results(self, image_rgb, segments, depth_map, total_nutrition, component_details):
        """å¯è¦–åŒ–çµæœï¼ˆæ”¯æŒä¸­æ–‡é¡¯ç¤ºï¼‰"""
        # è¨­ç½®ä¸­æ–‡å­—é«”
        # Windows ç³»çµ±å¸¸ç”¨ä¸­æ–‡å­—é«”
        chinese_fonts = [
            'Microsoft YaHei',      # å¾®è»Ÿé›…é»‘
            'SimHei',                # é»‘é«”
            'SimSun',                # å®‹é«”
            'KaiTi',                 # æ¥·é«”
            'FangSong',              # ä»¿å®‹
            'Arial Unicode MS',      # Arial Unicode MS
        ]
        
        # å˜—è©¦è¨­ç½®ä¸­æ–‡å­—é«”
        font_set = False
        for font_name in chinese_fonts:
            try:
                plt.rcParams['font.sans-serif'] = [font_name]
                plt.rcParams['axes.unicode_minus'] = False  # è§£æ±ºè² è™Ÿé¡¯ç¤ºå•é¡Œ
                # æ¸¬è©¦å­—é«”æ˜¯å¦å¯ç”¨
                fig_test = plt.figure(figsize=(1, 1))
                ax_test = fig_test.add_subplot(111)
                ax_test.text(0.5, 0.5, 'æ¸¬è©¦', fontsize=10)
                plt.close(fig_test)
                font_set = True
                print(f"  ä½¿ç”¨å­—é«”: {font_name}")
                break
            except:
                continue
        
        if not font_set:
            print("  âš ï¸ è­¦å‘Š: ç„¡æ³•è¨­ç½®ä¸­æ–‡å­—é«”ï¼Œä¸­æ–‡å¯èƒ½é¡¯ç¤ºç‚ºæ–¹æ¡†")
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        
        # å‰µå»ºåœ–å½¢
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('æ²™æ‹‰ç‡Ÿé¤Šåˆ†æå ±å‘Š', fontsize=18, fontweight='bold', y=0.98)
        
        # åŸå§‹åœ–åƒ
        axes[0, 0].imshow(image_rgb)
        axes[0, 0].set_title('åŸå§‹åœ–åƒ', fontsize=14, fontweight='bold')
        axes[0, 0].axis('off')
        
        # åˆ†å‰²çµæœï¼ˆå¸¶è—è‰²é‚Šæ¡†ï¼‰
        segmented_image = image_rgb.copy().astype(np.float32)
        colors = plt.cm.Set3(np.linspace(0, 1, len(segments)))
        h, w = image_rgb.shape[:2]
        
        for i, segment_mask in enumerate(segments):
            # æ·»åŠ åŠé€æ˜é¡è‰²è¦†è“‹
            segmented_image[segment_mask] = segmented_image[segment_mask] * 0.6 + \
                                            np.array(colors[i][:3]) * 255 * 0.4
            
            # ç¹ªè£½è—è‰²é‚Šç·£ç·šï¼ˆæ²¿è‘—å¯¦éš›è¼ªå»“ï¼‰
            mask_uint8 = (segment_mask.astype(np.uint8) * 255)
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            edge_thickness = max(2, int(min(h, w) / 400))
            
            # è½‰æ›ç‚ºBGRæ ¼å¼ä»¥ä¾¿ä½¿ç”¨cv2.drawContours
            segmented_image_bgr = cv2.cvtColor(segmented_image.astype(np.uint8), cv2.COLOR_RGB2BGR)
            cv2.drawContours(segmented_image_bgr, contours, -1, (255, 0, 0), edge_thickness)
            segmented_image = cv2.cvtColor(segmented_image_bgr, cv2.COLOR_BGR2RGB).astype(np.float32)
        
        axes[0, 1].imshow(segmented_image.astype(np.uint8))
        axes[0, 1].set_title(f'SAMåˆ†å‰²çµæœ ({len(segments)} å€‹å€åŸŸ)', fontsize=14, fontweight='bold')
        axes[0, 1].axis('off')
        
        # æ·±åº¦åœ–
        im = axes[1, 0].imshow(depth_map, cmap='viridis')
        axes[1, 0].set_title('DPT-Hybrid æ·±åº¦åœ–', fontsize=14, fontweight='bold')
        axes[1, 0].axis('off')
        plt.colorbar(im, ax=axes[1, 0], fraction=0.046, pad=0.04)
        
        # ç‡Ÿé¤Šæ•¸æ“š
        axes[1, 1].axis('off')
        axes[1, 1].set_facecolor('#f0f0f0')
        
        # æ§‹å»ºç‡Ÿé¤Šæ•¸æ“šæ–‡æœ¬
        nutrition_text = f"""ç¸½ç‡Ÿé¤Šæ•¸æ“š
{'='*30}
ç¸½é‡é‡: {total_nutrition['weight']:.1f} å…‹

ç†±é‡: {total_nutrition['calories']:.1f} å¤§å¡
è›‹ç™½è³ª: {total_nutrition['protein']:.1f} å…‹
ç¢³æ°´åŒ–åˆç‰©: {total_nutrition['carbs']:.1f} å…‹
è„‚è‚ª: {total_nutrition['fat']:.1f} å…‹
çº–ç¶­: {total_nutrition['fiber']:.1f} å…‹

æˆåˆ†è©³æƒ…:"""
        
        for comp in component_details:
            nutrition_text += f"\nâ€¢ {comp['type']}: {comp['weight_g']:.1f}å…‹ ({comp['calories']:.1f}å¤§å¡)"
        
        # ä½¿ç”¨æ”¯æŒä¸­æ–‡çš„å­—é«”é¡¯ç¤ºæ–‡æœ¬ï¼ˆç§»é™¤ monospaceï¼Œä½¿ç”¨ä¸­æ–‡å­—é«”ï¼‰
        axes[1, 1].text(0.05, 0.95, nutrition_text, fontsize=11, 
                        verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9),
                        family=plt.rcParams['font.sans-serif'][0] if font_set else 'sans-serif')
        
        plt.tight_layout(rect=[0, 0, 1, 0.97])  # ç‚ºæ¨™é¡Œç•™å‡ºç©ºé–“
        result_path = os.path.join(self.result_dir, '05_final_analysis_result.png')
        plt.savefig(result_path, dpi=150, bbox_inches='tight', facecolor='white')
        print(f"\nâœ“ æœ€çµ‚çµæœå·²ä¿å­˜åˆ°: {result_path}")
        plt.close()  # é—œé–‰åœ–å½¢ä»¥é¿å…é¡¯ç¤ºï¼ˆå¦‚æœéœ€è¦é¡¯ç¤ºå¯ä»¥æ”¹ç‚ºplt.show()ï¼‰


def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 50)
    print("æ²™æ‹‰ç‡Ÿé¤Šåˆ†æç³»çµ±")
    print("=" * 50)
    
    # åˆå§‹åŒ–åˆ†æå™¨ï¼ˆæœƒè‡ªå‹•æŸ¥æ‰¾SAMæ¨¡å‹æ–‡ä»¶ï¼‰
    analyzer = SaladNutritionAnalyzer(sam_checkpoint_path=None)
    
    # ç¤ºä¾‹ï¼šåˆ†æåœ–åƒ
    # è«‹æ›¿æ›ç‚ºæ‚¨çš„æ²™æ‹‰åœ–åƒè·¯å¾‘
    image_path = input("è«‹è¼¸å…¥æ²™æ‹‰åœ–åƒè·¯å¾‘ï¼ˆæˆ–æŒ‰Enterä½¿ç”¨æ¸¬è©¦æ¨¡å¼ï¼‰: ").strip()
    
    if not image_path:
        print("æœªæä¾›åœ–åƒè·¯å¾‘ï¼Œè«‹åœ¨ä»£ç¢¼ä¸­æŒ‡å®šåœ–åƒè·¯å¾‘")
        return
    
    # åŸ·è¡Œåˆ†æ
    try:
        total_nutrition, component_details = analyzer.analyze_salad(image_path)
        
        # æ‰“å°çµæœ
        print("\n" + "=" * 50)
        print("ç‡Ÿé¤Šåˆ†æçµæœ")
        print("=" * 50)
        print(f"ç¸½é‡é‡: {total_nutrition['weight']:.1f} å…‹")
        print(f"ç¸½ç†±é‡: {total_nutrition['calories']:.1f} å¤§å¡")
        print(f"è›‹ç™½è³ª: {total_nutrition['protein']:.1f} å…‹")
        print(f"ç¢³æ°´åŒ–åˆç‰©: {total_nutrition['carbs']:.1f} å…‹")
        print(f"è„‚è‚ª: {total_nutrition['fat']:.1f} å…‹")
        print(f"çº–ç¶­: {total_nutrition['fiber']:.1f} å…‹")
        print("\næˆåˆ†è©³æƒ…:")
        for comp in component_details:
            print(f"  - {comp['type']}: {comp['weight_g']:.1f}å…‹ "
                  f"({comp['calories']:.1f}å¤§å¡)")
        
    except Exception as e:
        print(f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

